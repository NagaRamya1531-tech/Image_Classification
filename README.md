# Image_Classification
# CIFAR-10 Image Classification Using CNN in PyTorch

This repository contains a Convolutional Neural Network (CNN) implementation for classifying images from the CIFAR-10 dataset. CIFAR-10 is a well-known benchmark dataset in the field of machine learning, consisting of 60,000 32x32 color images across 10 classes. Each class represents common objects encountered in everyday life, covering a diverse range of visual concepts.

## Dataset

The CIFAR-10 dataset consists of the following classes:
- Airplane
- Automobile
- Bird
- Cat
- Deer
- Dog
- Frog
- Horse
- Ship
- Truck

The dataset is split into:
- **Training Set:** 50,000 images
- **Test Set:** 10,000 images

Each class has an equal number of images in both the training and test sets.

## Why CNN?

CNNs have proven to be highly effective in image classification tasks due to their ability to automatically learn hierarchical features from raw pixel data. By leveraging convolutional layers, pooling layers, and fully connected layers, CNNs can capture intricate patterns and spatial relationships within images, making them well-suited for tasks like CIFAR-10 classification.



## Data Preparation and Augmentation

To enhance the model's performance, several data augmentation techniques are applied using PyTorchâ€™s `transforms` module:

- **Horizontal Image Flipping:** Randomly flips images horizontally with a 50% probability.
- **Image Rotation:** Randomly rotates images up to 20 degrees.
- **Brightness and Color Change:** Adjusts the brightness, contrast, and saturation of the images.
- **Sharpness Variation:** Randomly adjusts the sharpness of the images.
- **Conversion to Tensor:** Converts images to tensors and scales their values to the range [0, 1].
- **Standardization:** Normalizes the images based on specified mean and standard deviation values.
- **Random Blank Spots:** Introduces random erasing with a 75% probability to make the model more robust.

These transformations help create a more varied and detailed dataset, leading to a more reliable and versatile CNN.

## Batch Size

Batch size is an important hyperparameter that affects the training dynamics:

- **Training Speed:** Larger batch sizes can speed up training, especially when using GPUs.
- **Randomness:** Smaller batch sizes introduce more randomness, which can help prevent the model from getting stuck in local minima.
- **Memory Usage:** Larger batch sizes require more memory.
- **Learning Efficiency:** Smaller batch sizes can improve generalization, while larger batch sizes may perform better on the training data.

## ResNet Model

The model used in this project is based on ResNet (Residual Network), a type of deep neural network designed to address the vanishing gradient problem by using shortcut connections that bypass certain layers. This allows the network to retain learned information from earlier layers, enabling deeper architectures to be effectively trained.

### Model Architecture

ResNet is built using a series of building blocks, each containing several layers designed to learn detailed features from images. The shortcut connections in ResNet allow the model to combine new information with what it has already learned, leading to better performance in deep networks. The specific ResNet variant used can be adjusted depending on the complexity of the task (e.g., ResNet-18, ResNet-34, ResNet-50, etc.).

## Model Training

### Hyperparameters

1. **Epochs (NUM_EPOCHS):** The number of times the entire training dataset passes through the network.
2. **Learning Rate (learning_rate):** Controls the step size for updating model weights.
3. **Weight Decay (weight_decay):** Prevents overfitting by penalizing large weights.
4. **Gradient Clipping (grad_clip):** Limits the maximum gradient to prevent the exploding gradient problem.
5. **Loss Function:** `nn.CrossEntropyLoss()` is used for measuring the model's performance.
6. **Optimizer:** `torch.optim.Adam` is used to adjust model parameters during training.
7. **Learning Rate Scheduler:** `torch.optim.lr_scheduler.ReduceLROnPlateau` adjusts the learning rate if the model's performance plateaus.

### Model Evaluation

The ResNet model demonstrates impressive performance on the CIFAR-10 dataset, achieving high accuracy, rapid convergence, and strong generalization capabilities. Continued training and fine-tuning could further enhance its predictive abilities.

## Getting Started

To get started with this project, clone the repository and install the required dependencies:

```bash
git clone https://github.com/yourusername/cifar10-cnn-pytorch.git
cd cifar10-cnn-pytorch
pip install -r requirements.txt
